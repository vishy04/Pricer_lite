{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cujSfOZPCnZA"
      },
      "outputs": [],
      "source": [
        "# pip installs\n",
        "\n",
        "%pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "%pip install -q --upgrade requests==2.32.4 bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 peft==0.14.0 trl==0.14.0 fsspec==2025.3.0 matplotlib wandb datasets\n",
        "\n",
        "print(\"Installation successfull.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQT5AGh0bA3M"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, set_seed, BitsAndBytesConfig\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import wandb\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yBxl-p369pA"
      },
      "outputs": [],
      "source": [
        "#project constants\n",
        "HF_USER = \"Vishy08\"\n",
        "PROJECT_NAME = \"product-pricer\"\n",
        "\n",
        "\n",
        "RUN_NAME = f\"{datetime.now() :%d-%m-%Y_%H.%M.%S}\"\n",
        "PROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\n",
        "HUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hf-login\n",
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "login(hf_token , add_to_git_credential = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#wandb setup\n",
        "LOG_TO_WANDB = True\n",
        "\n",
        "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
        "os.environ['WANDB_API_KEY'] = wandb_api_key\n",
        "wandb.login()\n",
        "\n",
        "os.environ[\"WANDB_PROJECT\"] = 'product-pricer'\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\" if LOG_TO_WANDB else \"end\"\n",
        "os.environ[\"WANDB_WATCH\"] = \"gradients\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#QLORA Parameters\n",
        "LORA_R = 32\n",
        "LORA_ALPHA = 64\n",
        "TARGET_MODULES = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
        "LORA_DROPOUT = 0.1\n",
        "QUANT_4_BIT = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hyperparameter\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 16\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "LR_SCHEDULER_TYPE = 'cosine'\n",
        "WARMUP_RATIO = 0.03\n",
        "OPTIMIZER = \"paged_adamw_32bit\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "STEPS = 50\n",
        "SAVE_STEPS = 2000\n",
        "LOG_TO_WANDB = True\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"Vishy08/pricer-data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_subset = dataset['train'].shuffle(seed=42).select(range(100000))\n",
        "val_dataset = dataset['val']\n",
        "\n",
        "print(f\"Train on: {len(train_subset)}\")\n",
        "print(f\"Val on: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trl import DataCollatorForCompletionOnlyLM\n",
        "response_template = \"Price is $\"\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model and Tokenizer Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEoxsLy9zcJR"
      },
      "outputs": [],
      "source": [
        "\n",
        "QUANT_4_BIT = True\n",
        "\n",
        "if QUANT_4_BIT:\n",
        "    quant_config = BitsAndBytesConfig(\n",
        "        load_in_4bit = True ,\n",
        "        bnb_4bit_use_double_quant = True ,\n",
        "        bnb_4bit_compute_dtype = torch.bfloat16 ,\n",
        "        bnb_4bit_quant_type = 'nf4' ,\n",
        "    )\n",
        "else :\n",
        "    quant_config = BitsAndBytesConfig(\n",
        "        load_in_8bit = True ,\n",
        "        bnb_8bit_compute_dtype = torch.bfloat16,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDfnF4GuOzZF"
      },
      "outputs": [],
      "source": [
        "\n",
        "#tokenizer\n",
        "BASE_MODEL = 'meta-llama/Llama-3.1-8B-Instruct'\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL , trust_remote_code = True )\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL  ,\n",
        "    quantization_config = quant_config ,\n",
        "    device_map = 'auto'\n",
        ")\n",
        "base_model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "print(base_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Restarting from a checkpoint( due to colab crash midway)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF7WmG-T7l1u"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(project = \"product-pricer\" , \n",
        "                resume = \"allow\" , \n",
        "                id = \"nxo7668d\")\n",
        "                \n",
        "artifact = run.use_artifact(\"llm_engineering/product-pricer/model-nxo7668d:v2\",type =\"model\")\n",
        "artifact_dir = artifact.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtgdSb6GVPHx"
      },
      "outputs": [],
      "source": [
        "# path to resume training from the artifact in wandb \n",
        "checkpoint_path = \"/content/artifacts/model-nxo7668d:v2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Starting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjdFo7H36yvG"
      },
      "outputs": [],
      "source": [
        "# LoRA Config\n",
        "lora_parameters = LoraConfig(\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    r=LORA_R,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=TARGET_MODULES,\n",
        ")\n",
        "\n",
        "# SFT Config\n",
        "train_parameters = SFTConfig(\n",
        "    output_dir=PROJECT_RUN_NAME,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=12,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    logging_steps=50,\n",
        "\n",
        "\n",
        "    report_to = 'wandb',\n",
        "\n",
        "    # Validation Settings\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    do_eval=True,\n",
        "\n",
        "    # Dataset Settings\n",
        "    max_seq_length= 1024,\n",
        "    dataset_text_field=\"prompt\",\n",
        "    packing=False,\n",
        "\n",
        "    # Hub / Saving\n",
        "    save_steps=500,\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=HUB_MODEL_NAME,\n",
        "    hub_private_repo=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vvehZRxAqlc"
      },
      "outputs": [],
      "source": [
        "#INITIALIZATION\n",
        "fine_tuning = SFTTrainer(\n",
        "    model=base_model,\n",
        "    train_dataset=train_subset,\n",
        "    eval_dataset=val_dataset,\n",
        "    peft_config=lora_parameters,\n",
        "    args=train_parameters,\n",
        "    data_collator=collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_G-PogwAoQM"
      },
      "outputs": [],
      "source": [
        "fine_tuning.train(resume_from_checkpoint=checkpoint_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
