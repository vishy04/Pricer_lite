{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cujSfOZPCnZA"
      },
      "outputs": [],
      "source": [
        "# pip installs\n",
        "\n",
        "!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q --upgrade requests==2.32.4 bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 peft==0.14.0 trl==0.14.0 fsspec==2025.3.0 matplotlib wandb datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, set_seed, BitsAndBytesConfig\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import wandb\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "MQT5AGh0bA3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_USER = \"Vishy08\"\n",
        "PROJECT_NAME = \"product-pricer\""
      ],
      "metadata": {
        "id": "1yBxl-p369pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOG_TO_WANDB = True\n",
        "RUN_NAME = f\"{datetime.now() :%d-%m-%Y_%H.%M.%S}\"\n",
        "PROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\n",
        "HUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\""
      ],
      "metadata": {
        "id": "SQGZ5I5awdZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "login(hf_token , add_to_git_credential = True)\n",
        "\n",
        "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
        "os.environ['WANDB_API_KEY'] = wandb_api_key\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "F3WEIYcRtDXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_PROJECT\"] = 'product-pricer'\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\" if LOG_TO_WANDB else \"end\"\n",
        "os.environ[\"WANDB_WATCH\"] = \"gradients\""
      ],
      "metadata": {
        "id": "z_uDmasTwQqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "QUANT_4_BIT = True\n",
        "\n",
        "if QUANT_4_BIT:\n",
        "    quant_config = BitsAndBytesConfig(\n",
        "        load_in_4bit = True ,\n",
        "        bnb_4bit_use_double_quant = True ,\n",
        "        bnb_4bit_compute_dtype = torch.bfloat16 ,\n",
        "        bnb_4bit_quant_type = 'nf4' ,\n",
        "    )\n",
        "else :\n",
        "    quant_config = BitsAndBytesConfig(\n",
        "        load_in_8bit = True ,\n",
        "        bnb_8bit_compute_dtype = torch.bfloat16,\n",
        "    )"
      ],
      "metadata": {
        "id": "AEoxsLy9zcJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#tokenizer\n",
        "BASE_MODEL = 'meta-llama/Llama-3.1-8B-Instruct'\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL , trust_remote_code = True )\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL  ,\n",
        "    quantization_config = quant_config ,\n",
        "    device_map = 'auto'\n",
        ")\n",
        "base_model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "print(base_model)"
      ],
      "metadata": {
        "id": "MDfnF4GuOzZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"Vishy08/pricer-data\")"
      ],
      "metadata": {
        "id": "JKgNYF5XR-sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainerCallback\n",
        "import torch\n",
        "import random\n",
        "\n",
        "class TestPromptCallback(TrainerCallback):\n",
        "    def __init__(self, tokenizer, val_dataset, num_samples=2):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.val_dataset = val_dataset\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def on_evaluate(self, args, state, control, **kwargs):\n",
        "        # This triggers whenever evaluation runs (e.g. every 50 or 100 steps)\n",
        "        print(f\"\\n--- VISUAL CHECK at Step {state.global_step} ---\")\n",
        "\n",
        "        # Select random samples from the validation set\n",
        "        indices = random.sample(range(len(self.val_dataset)), self.num_samples)\n",
        "        model = kwargs['model']\n",
        "        model.eval() # Switch to evaluation mode\n",
        "\n",
        "        for idx in indices:\n",
        "            sample = self.val_dataset[idx]\n",
        "            # Use 'test_prompt' which has NO answer (e.g. \"... Price is $\")\n",
        "            input_text = sample['test_prompt']\n",
        "\n",
        "            inputs = self.tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Generate up to 10 tokens (enough for a price)\n",
        "                outputs = model.generate(**inputs, max_new_tokens=10, pad_token_id=self.tokenizer.pad_token_id)\n",
        "\n",
        "            # Decode the result\n",
        "            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            prediction = generated_text.replace(input_text, \"\").strip()\n",
        "\n",
        "            print(f\"Sample {idx}:\")\n",
        "            print(f\"Input:     {input_text.strip()} [ends here]\")\n",
        "            print(f\"Predicted: {prediction}\")\n",
        "            print(f\"Actual:    {sample['price']}\") # Compare with hidden truth\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "        model.train() # Switch back to training mode\n",
        "\n",
        "# Initialize the callback with your validation set\n",
        "# We will pass this to the trainer in the next block\n",
        "printer_callback = TestPromptCallback(tokenizer, dataset['val'])"
      ],
      "metadata": {
        "id": "dgTIsefG6c2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_subset = dataset['train'].shuffle(seed=42).select(range(100000))\n",
        "val_dataset = dataset['val']\n",
        "\n",
        "print(f\"Train on: {len(train_subset)}\")\n",
        "print(f\"Val on: {len(val_dataset)}\")"
      ],
      "metadata": {
        "id": "H4xq6M_j6olv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#QLORA Parameters\n",
        "LORA_R = 32\n",
        "LORA_ALPHA = 64\n",
        "TARGET_MODULES = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
        "LORA_DROPOUT = 0.1\n",
        "QUANT_4_BIT = True"
      ],
      "metadata": {
        "id": "_hwB1iOa7O4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 16\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "LR_SCHEDULER_TYPE = 'cosine'\n",
        "WARMUP_RATIO = 0.03\n",
        "OPTIMIZER = \"paged_adamw_32bit\""
      ],
      "metadata": {
        "id": "ef097z7T7V0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STEPS = 50\n",
        "SAVE_STEPS = 2000\n",
        "LOG_TO_WANDB = True\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "9rWIOxrk7hyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project = \"product-pricer\" , resume = \"allow\" , id = \"nxo7668d\")\n"
      ],
      "metadata": {
        "id": "aF7WmG-T7l1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artifact = run.use_artifact(\"llm_engineering/product-pricer/model-nxo7668d:v2\",type =\"model\")\n",
        "artifact_dir = artifact.download()"
      ],
      "metadata": {
        "id": "y2lcnU5RRIRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import DataCollatorForCompletionOnlyLM\n",
        "response_template = \"Price is $\"\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "jPH-1Ih38afd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA Config\n",
        "lora_parameters = LoraConfig(\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    r=LORA_R,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=TARGET_MODULES,\n",
        ")\n",
        "\n",
        "# SFT Config\n",
        "train_parameters = SFTConfig(\n",
        "    output_dir=PROJECT_RUN_NAME,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=12,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    logging_steps=50,\n",
        "\n",
        "\n",
        "    report_to = 'wandb',\n",
        "\n",
        "    # Validation Settings\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    do_eval=True,\n",
        "\n",
        "    # Dataset Settings\n",
        "    max_seq_length= 1024,\n",
        "    dataset_text_field=\"prompt\",\n",
        "    packing=False,\n",
        "\n",
        "    # Hub / Saving\n",
        "    save_steps=500,\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=HUB_MODEL_NAME,\n",
        "    hub_private_repo=True\n",
        ")"
      ],
      "metadata": {
        "id": "QjdFo7H36yvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#INITIALIZATION\n",
        "fine_tuning = SFTTrainer(\n",
        "    model=base_model,\n",
        "    train_dataset=train_subset,\n",
        "    eval_dataset=val_dataset,\n",
        "    peft_config=lora_parameters,\n",
        "    args=train_parameters,\n",
        "    data_collator=collator,\n",
        "    callbacks=[printer_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "9vvehZRxAqlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Point to the folder shown in your file explorer screenshot\n",
        "checkpoint_path = \"/content/artifacts/model-nxo7668d:v2\""
      ],
      "metadata": {
        "id": "dtgdSb6GVPHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuning.train(resume_from_checkpoint=checkpoint_path)"
      ],
      "metadata": {
        "id": "D_G-PogwAoQM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}